/**
 * æ–‡æ¡£çŸ¥è¯†åº“æ„å»ºè„šæœ¬
 * 
 * åŠŸèƒ½ï¼š
 * - è¯»å–æ‰€æœ‰ä¸­æ–‡ Markdown æ–‡æ¡£
 * - æŒ‰æ ‡é¢˜ï¼ˆ## / ###ï¼‰æ‹†åˆ†ä¸ºç‹¬ç«‹ç‰‡æ®µ
 * - æå–å…³é”®è¯ç”¨äºæœç´¢åŒ¹é…
 * - è¾“å‡º data/knowledge.json ä¾› Worker ä½¿ç”¨
 * 
 * ç”¨æ³•ï¼šnode scripts/build-knowledge.js
 */

import { readFileSync, readdirSync, statSync, writeFileSync, mkdirSync, existsSync } from 'fs'
import { join, relative, basename } from 'path'

/* æ–‡æ¡£æ ¹ç›®å½•ï¼ˆç›¸å¯¹äºæœ¬è„šæœ¬ï¼‰ */
const DOCS_ROOT = join(import.meta.dirname, '..', '..', '..')

/* æ’é™¤çš„ç›®å½•å’Œæ–‡ä»¶ */
const EXCLUDE_DIRS = ['node_modules', 'dist', '.vitepress', 'en', 'workers', 'public']
const EXCLUDE_FILES = ['README.md']

/* ä¸­æ–‡åœç”¨è¯ï¼ˆæœç´¢æ—¶å¿½ç•¥ï¼‰ */
const STOP_WORDS = new Set([
  'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸€ä¸ª',
  'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'è¯´', 'è¦', 'å»', 'ä½ ', 'ä¼š', 'ç€', 'æ²¡æœ‰', 'çœ‹', 'å¥½',
  'è‡ªå·±', 'è¿™', 'ä»–', 'å¥¹', 'å®ƒ', 'ä»¬', 'é‚£', 'äº›', 'ä»€ä¹ˆ', 'æ€ä¹ˆ', 'å¦‚ä½•', 'ä¸ºä»€ä¹ˆ',
  'å¯ä»¥', 'èƒ½', 'å—', 'å‘¢', 'å§', 'å•Š', 'å“¦', 'å—¯', 'è¯·é—®', 'è¯·',
  'the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been', 'being',
  'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',
  'should', 'may', 'might', 'can', 'to', 'of', 'in', 'for', 'on', 'with',
  'at', 'by', 'from', 'as', 'into', 'through', 'during', 'before', 'after',
  'and', 'but', 'or', 'not', 'no', 'if', 'then', 'else', 'when', 'up',
  'this', 'that', 'these', 'those', 'it', 'its',
])

/**
 * @description é€’å½’æ‰«æç›®å½•ï¼Œæ”¶é›†æ‰€æœ‰ .md æ–‡ä»¶è·¯å¾„
 */
function collectMarkdownFiles(dir, files = []) {
  const entries = readdirSync(dir)
  for (const entry of entries) {
    const fullPath = join(dir, entry)
    const stat = statSync(fullPath)

    if (stat.isDirectory()) {
      if (!EXCLUDE_DIRS.includes(entry)) {
        collectMarkdownFiles(fullPath, files)
      }
    } else if (entry.endsWith('.md') && !EXCLUDE_FILES.includes(entry)) {
      files.push(fullPath)
    }
  }
  return files
}

/**
 * @description ä»æ–‡ä»¶è·¯å¾„æ¨æ–­é¡µé¢åˆ†ç±»
 */
function getCategory(filePath) {
  const rel = relative(DOCS_ROOT, filePath).replace(/\\/g, '/')
  const parts = rel.split('/')
  if (parts.length > 1) {
    const categoryMap = {
      'guide': 'ä½¿ç”¨æŒ‡å—',
      'config': 'é…ç½®è¯´æ˜',
      'architecture': 'ç³»ç»Ÿæ¶æ„',
      'api': 'API å‚è€ƒ',
      'tools': 'å·¥å…·å¼€å‘',
      'deploy': 'éƒ¨ç½²æ•™ç¨‹',
    }
    return categoryMap[parts[0]] || parts[0]
  }
  return 'é€šç”¨'
}

/**
 * @description ä» Markdown å†…å®¹ä¸­æå–é¡µé¢æ ‡é¢˜ï¼ˆç¬¬ä¸€ä¸ª # æ ‡é¢˜ï¼‰
 */
function extractPageTitle(content) {
  const match = content.match(/^#\s+(.+?)(\s*\{#.*\})?$/m)
  return match ? match[1].replace(/<[^>]+>/g, '').trim() : ''
}

/**
 * @description å°† Markdown æŒ‰æ ‡é¢˜æ‹†åˆ†ä¸ºç‰‡æ®µ
 */
function splitIntoChunks(content, filePath) {
  const pageTitle = extractPageTitle(content)
  const category = getCategory(filePath)
  const relPath = relative(DOCS_ROOT, filePath).replace(/\\/g, '/')
  const chunks = []

  /* æ¸…ç† Markdown ä¸­çš„ VitePress ç‰¹æ®Šè¯­æ³• */
  const cleaned = content
    .replace(/^---[\s\S]*?---/m, '')
    .replace(/::: (tip|warning|danger|info|details).*?\n/g, '')
    .replace(/:::/g, '')
    .replace(/<Badge[^>]*\/>/g, '')
    .replace(/```mermaid[\s\S]*?```/g, '')
    .trim()

  /* æŒ‰ ## æ ‡é¢˜æ‹†åˆ† */
  const sections = cleaned.split(/^(?=##\s)/m)

  for (const section of sections) {
    const trimmed = section.trim()
    if (!trimmed || trimmed.length < 20) continue

    /* æå–ç« èŠ‚æ ‡é¢˜ */
    const titleMatch = trimmed.match(/^##\s+(.+?)(\s*\{#.*\})?$/m)
    const sectionTitle = titleMatch
      ? titleMatch[1].replace(/<[^>]+>/g, '').trim()
      : pageTitle

    /* è¿›ä¸€æ­¥æŒ‰ ### æ‹†åˆ†å¤§ç« èŠ‚ */
    const subSections = trimmed.split(/^(?=###\s)/m)

    for (const sub of subSections) {
      const subTrimmed = sub.trim()
      if (!subTrimmed || subTrimmed.length < 15) continue

      const subTitleMatch = subTrimmed.match(/^###\s+(.+?)(\s*\{#.*\})?$/m)
      const subTitle = subTitleMatch
        ? subTitleMatch[1].replace(/<[^>]+>/g, '').trim()
        : null

      /* æ¸…ç†å†…å®¹ï¼šå»é™¤ HTML æ ‡ç­¾ã€å¤šä½™ç©ºè¡Œ */
      const cleanContent = subTrimmed
        .replace(/<[^>]+>/g, '')
        .replace(/\n{3,}/g, '\n\n')
        .trim()

      /* è·³è¿‡è¿‡çŸ­çš„ç‰‡æ®µ */
      if (cleanContent.length < 30) continue

      /* æˆªæ–­è¿‡é•¿çš„ç‰‡æ®µï¼ˆä¿æŒåˆç†çš„ä¸Šä¸‹æ–‡å¤§å°ï¼‰ */
      const finalContent = cleanContent.length > 2000
        ? cleanContent.substring(0, 2000) + '...'
        : cleanContent

      const fullTitle = subTitle
        ? `${pageTitle} > ${sectionTitle} > ${subTitle}`
        : `${pageTitle} > ${sectionTitle}`

      chunks.push({
        title: fullTitle,
        pageTitle,
        category,
        path: relPath,
        content: finalContent,
        keywords: extractKeywords(fullTitle + ' ' + finalContent),
      })
    }
  }

  /* å¦‚æœæ²¡æœ‰æ‹†åˆ†å‡ºç‰‡æ®µï¼ˆå¯èƒ½æ˜¯æ²¡æœ‰äºŒçº§æ ‡é¢˜çš„å°æ–‡ä»¶ï¼‰ï¼Œæ•´ä½“ä½œä¸ºä¸€ä¸ªç‰‡æ®µ */
  if (chunks.length === 0 && cleaned.length > 30) {
    const finalContent = cleaned.length > 2000
      ? cleaned.substring(0, 2000) + '...'
      : cleaned

    chunks.push({
      title: pageTitle || basename(filePath, '.md'),
      pageTitle: pageTitle || basename(filePath, '.md'),
      category,
      path: relPath,
      content: finalContent,
      keywords: extractKeywords(pageTitle + ' ' + finalContent),
    })
  }

  return chunks
}

/**
 * @description ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯ï¼ˆç”¨äºæœç´¢åŒ¹é…ï¼‰
 */
function extractKeywords(text) {
  /* æå–è‹±æ–‡å•è¯å’Œä¸­æ–‡è¯æ±‡ */
  const words = new Set()

  /* è‹±æ–‡å•è¯ï¼ˆ2+ å­—ç¬¦ï¼‰ */
  const englishWords = text.match(/[a-zA-Z][a-zA-Z0-9_-]{1,}/g) || []
  for (const w of englishWords) {
    const lower = w.toLowerCase()
    if (!STOP_WORDS.has(lower) && lower.length >= 2) {
      words.add(lower)
    }
  }

  /* ä¸­æ–‡åˆ†è¯ï¼ˆç®€å•çš„ 2-4 å­—ç»„åˆï¼‰ */
  const chineseChars = text.replace(/[^\u4e00-\u9fff]/g, '')
  for (let i = 0; i < chineseChars.length - 1; i++) {
    const bigram = chineseChars.substring(i, i + 2)
    if (!STOP_WORDS.has(bigram)) {
      words.add(bigram)
    }
    if (i < chineseChars.length - 2) {
      words.add(chineseChars.substring(i, i + 3))
    }
  }

  return [...words]
}

/* ==================== ä¸»æµç¨‹ ==================== */
function main() {
  console.log('ğŸ“š å¼€å§‹æ„å»ºæ–‡æ¡£çŸ¥è¯†åº“...')
  console.log(`æ–‡æ¡£ç›®å½•: ${DOCS_ROOT}`)

  const mdFiles = collectMarkdownFiles(DOCS_ROOT)
  console.log(`æ‰¾åˆ° ${mdFiles.length} ä¸ª Markdown æ–‡ä»¶`)

  let allChunks = []

  for (const file of mdFiles) {
    const content = readFileSync(file, 'utf-8')
    const chunks = splitIntoChunks(content, file)
    allChunks.push(...chunks)
    console.log(`  âœ… ${relative(DOCS_ROOT, file)} â†’ ${chunks.length} ä¸ªç‰‡æ®µ`)
  }

  /* ä¸ºæ¯ä¸ªç‰‡æ®µæ·»åŠ å”¯ä¸€ ID */
  allChunks = allChunks.map((chunk, idx) => ({
    id: idx,
    ...chunk,
  }))

  /* è¾“å‡ºç»Ÿè®¡ */
  const totalSize = JSON.stringify(allChunks).length
  console.log(`\nğŸ“Š çŸ¥è¯†åº“ç»Ÿè®¡:`)
  console.log(`  ç‰‡æ®µæ€»æ•°: ${allChunks.length}`)
  console.log(`  JSON å¤§å°: ${(totalSize / 1024).toFixed(1)} KB`)

  /* å†™å…¥æ–‡ä»¶ */
  const outputDir = join(import.meta.dirname, '..', 'data')
  if (!existsSync(outputDir)) {
    mkdirSync(outputDir, { recursive: true })
  }

  const outputPath = join(outputDir, 'knowledge.json')
  writeFileSync(outputPath, JSON.stringify(allChunks), 'utf-8')
  console.log(`\nâœ… çŸ¥è¯†åº“å·²å†™å…¥: ${outputPath}`)
}

main()
